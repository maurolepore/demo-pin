---
output: github_document
---

# Managing data better with pins

Relates to our [discussion on managing and using data](https://github.com/2DegreesInvesting/ds-incubator/issues/35), and extends a previous [introduction to the pins package](https://github.com/2DegreesInvesting/ds-incubator/issues/38).

Here I show how pins meets these requirements:

- [x] Plays well with R.
- [x] Is low cost or better free.
- [x] Data hosted online can also be accessed from a local cache.
- [x] Allows us to control permissions to read and write data.
- [x] Supports version control with Git and GitHub.
- [x] Can handle datasets of the maximum size we need.

tl;dr:

* The pins package meets all requirements with some caveats.
* `pin()`: Pin remote resources locally, work offline and cache results.
* `pin_find()`: Discover new resources across different boards.
* `board_register()`: Share resources in local folders, GitHub, Azure, and more.
* Learn more at <https://pins.rstudio.com/>.

### Plays well with R

It is an [R package](https://cloud.r-project.org/web/packages/pins/index.html), and well integrated with RStudio.

```{r}
# install.packages("pins")
library(pins)
```

Here I also use a few other packages for convenience.

```{r}
library(glue)
library(readr)
library(fs)
library(dplyr, warn.conflicts = FALSE)
```

### Is low cost or better free

As any other R package, pins is free, but [can be used with paid services, e.g. Azure](https://pins.rstudio.com/articles/boards-azure.html).

### Data hosted online can also be accessed from a local cache

Consider a dataset stored online:

* [Nice view](https://github.com/tidyverse/readr/blob/master/inst/extdata/mtcars.csv).
* [Raw view](https://raw.githubusercontent.com/tidyverse/readr/master/inst/extdata/mtcars.csv)

You don't need pins to download or read this file. You may do it with `download.file()` and `read.csv()` (I prefer `readr::read_csv()`). But every time the process may potentially take a long time.

```{r, message=FALSE}
url <- "https://raw.githubusercontent.com/tidyverse/readr/master/inst/extdata/mtcars.csv"
url %>% read_csv()
```

A better way is to `pin()` the URL, which creates a cache in a local "board" that you can later use.

```{r, message=FALSE}
url %>% pin("my_data")

# Works from any R session
my_data <- pin_get("my_data") %>% read_csv()
my_data
```
> `pin()` still works when working offline or when the remote resource becomes unavailable; when this happens, a warning will be triggered but your code will continue to work.

The default location for the local-board cache is convenient and sensible.

```{r}
board_default()

dir_tree(board_cache_path())
```

But you may want to instead use another location, and enable [pins versions](https://pins.rstudio.com/articles/advanced-versions.html).

```{r}
my_cache <- path(tempdir(), "pins_cache")

board_register_local(
  name = "my_local_board", 
  cache = my_cache, 
  versions = TRUE
)

my_data %>% 
  filter(cyl > 6) %>% 
  # Cache new version
  pin(name = "my_data", board = "my_local_board") %>%  
  select(mpg, gear) %>% 
  # Cache new version
  pin(name = "my_data", board = "my_local_board") 

history <- pin_versions("my_data", board = "my_local_board")
history

latest <- history$version[1]
dim(pin_get("my_data", board = "my_local_board", version = latest))

older <- history$version[2]
dim(pin_get("my_data", board = "my_local_board", version = older))
```

In case you are curious, this is the structure of pins versions.

```{r}
dir_tree(my_cache)
```

### Supports version control with Git

For more control, initialize a Git repository in your pins cache.

```{r}
# Set environmental variable so I can use it from the terminal
Sys.setenv(MY_CACHE = my_cache)
Sys.getenv("MY_CACHE")
```

From the terminal:

```{r git, echo=TRUE, engine='/bin/bash'}
git init $MY_CACHE
cd $MY_CACHE
git add .
git commit -m "Start tracking my cache with Git"
```

As usual, you may now push your Git repository to GitHub.

But GitHub repos can better serve you as a pins board. This works both for public and private repos.

```{r engine="/bin/bash", include=FALSE}
gh repo create maurolepore/demo-board --public
```
For example:

```{r}
board_register_github(
  name = "my_github_board",
  repo = "maurolepore/demo-board",
  cache = my_cache,
  versions = TRUE
)

my_data %>% 
  pin(
    name = "my_data",
    board = "my_github_board",
    description = "Some data",
    repo = "maurolepore/demo-board"
  )

pin_find("my_data", board = "my_github_board")

pin_get("my_data", board = "my_github_board")
```

Worst case scenario you can always get data directly from your local cache.

```{r}
dir_tree(my_cache)

path(my_cache, "my_github_board", "my_data", "data.rds") %>% read_rds()
```

### Allows us to control permissions to read and write data

It is not pins job to control who reads or writes data but it plays well with tools like Azure and GitHub that provide granular [access permissions](https://help.github.com/en/github/getting-started-with-github/access-permissions-on-github).

### Can handle datasets of the maximum size we need

Pins has no limit but some boards do. [Azure](https://pins.rstudio.com/articles/boards-azure.html) is apparently limitless but charges for what it hosts. On [GitHub](https://pins.rstudio.com/articles/boards-github.html) pins can host files up to 2GB in both public and private repos.

--

Cleanup.

```{r, engine="/bin/bash"}
trash $MY_CACHE
```
