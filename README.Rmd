---
output: github_document
---

# Managing data better with pins

Relates to our [discussion on managing and using data](https://github.com/2DegreesInvesting/ds-incubator/issues/35), and extends a previous [introduction to the pins package](https://github.com/2DegreesInvesting/ds-incubator/issues/38).

Here I show how pins meets these requirements:

- [x] Plays well with R.
- [x] Is low cost or better free.
- [x] Data hosted online can also be accessed from a local cache.
- [x] Allows us to control permissions to read and write data.
- [x] Supports version control with Git and GitHub.
- [x] Can handle datasets of the maximum size we need.

tl;dr:

* The pins package meets all requirements with some caveats.
* `pin()`: Pin remote resources locally, work offline and cache results.
* `pin_find()`: Discover new resources across different boards.
* `board_register()`: Share resources in local folders, GitHub, Azure, and more.
* Learn more at <https://pins.rstudio.com/>.

### Plays well with R

It is an [R package](https://cloud.r-project.org/web/packages/pins/index.html), and well integrated with RStudio.

```{r}
# install.packages("pins")
library(pins)
```

Here I also use a few other packages for convenience.

```{r}
library(glue)
library(readr)
library(fs)
library(dplyr, warn.conflicts = FALSE)
```

### Is low cost or better free

As any other R package, pins is free, but [can be used with paid services, e.g. Azure](https://pins.rstudio.com/articles/boards-azure.html).

### Data hosted online can also be accessed from a local cache

Consider a dataset stored online:

* [Nice view](https://github.com/tidyverse/readr/blob/master/inst/extdata/mtcars.csv).
* [Raw view](https://raw.githubusercontent.com/tidyverse/readr/master/inst/extdata/mtcars.csv)

You don't need pins to download or read this file. You may do it with `download.file()` and `read.csv()` (I prefer `readr::read_csv()`). But every time the process may potentially take a long time.

```{r, message=FALSE}
raw_url <- 
  "https://raw.githubusercontent.com/tidyverse/readr/master/inst/extdata/mtcars.csv"

# First time
system.time(read_csv(raw_url))

# Second time
system.time(read_csv(raw_url))
```

A better way is to `pin()` the URL.

```{r, message=FALSE}
# First time
system.time(read_csv(pin(raw_url)))

# Second time
system.time(read_csv(pin(raw_url)))
```

The first time pins creates a cache in a local "board" and reuses it the second time -- which runs faster.

```{r}
pins::board_default()

fs::dir_tree(pins::board_cache_path())
```

The default location for the local-board cache is convenient and sensible, but you may want to instead use another location.

```{r}
my_cache <- fs::path(tempdir(), "pins_cache")
board_register_local(
  name = "my_local_board", 
  cache = my_cache, 
  versions = TRUE
)
```

`versions = TRUE` enables [pins versions](https://pins.rstudio.com/articles/advanced-versions.html).

You can pin a dataset at different after you read it, and get it from your cache into any R session.

```{r, message=FALSE}
read_csv(raw_url) %>% 
  pin(name = "my_data", board = "my_local_board")

# Sometime, somewhere
my_data <- pin_get(name = "my_data", board = "my_local_board")
my_data
```

And you can pin different versions, which might be difficult or slow to re-compute.

```{r, message=FALSE}
my_data %>% 
  filter(cyl > 6) %>% 
  # Cache new version
  pin(name = "my_data", board = "my_local_board") %>%  
  select(mpg, gear) %>% 
  # Cache new version
  pin(name = "my_data", board = "my_local_board") 

history <- pins::pin_versions("my_data", board = "my_local_board")
history

latest <- history$version[1]
dim(pin_get("my_data", board = "my_local_board", version = latest))

older <- history$version[2]
dim(pin_get("my_data", board = "my_local_board", version = older))
```

In case you are curious, this is the structure of pins versions.

```{r}
fs::dir_tree(my_cache)
```

### Supports version control with Git

For more control, initialize a Git repository in your pins cache.

```{r, engine="/bin/bash"}
git init /tmp/Rtmpdrvnwb/pins_cache
```

On the terminal I can now change directory to my pins_cache, add all changes, commit, and inspect the log:

```{r echo=TRUE, engine="/bin/bash"}
cd /tmp/Rtmpdrvnwb/pins_cache
git add .
git commit -m "Start tracking my cache with Git"
```

### Allows us to control permissions to read and write data

It is not pins job to control who reads or writes data but it plays well with tools like Azure and GitHub that provide granular [access permissions](https://help.github.com/en/github/getting-started-with-github/access-permissions-on-github).

### Can handle datasets of the maximum size we need

Pins has no limit but some boards do. [Azure](https://pins.rstudio.com/articles/boards-azure.html) is apparently limitless but charges for what it hosts. On [GitHub](https://pins.rstudio.com/articles/boards-github.html) pins can host files up to 2GB in both public and private repos.

--

Cleanup.

```{r, engine="/bin/bash"}
trash /tmp/Rtmpdrvnwb/pins_cache
```


